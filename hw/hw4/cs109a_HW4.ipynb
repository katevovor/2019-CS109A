{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science\n",
    "\n",
    "## Homework 4: Logistic Regression\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2019**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader, and Chris Tanner\n",
    "\n",
    "<hr style=\"height:2pt\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- **This is an individual homework. No group collaboration.**\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list.\n",
    "- Please use .head() when viewing data. Do not submit a notebook that is excessively long because output was not suppressed or otherwise limited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import zipfile\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='theme'> Cancer Classification from Gene Expressions </div>\n",
    "\n",
    "In this problem, we will build a classification model to distinguish between two related classes of cancer, acute lymphoblastic leukemia (ALL) and acute myeloid leukemia (AML), using gene expression measurements. The data set is provided in the file `data/dataset_hw4.csv`. Each row in this file corresponds to a tumor tissue sample from a patient with one of the two forms of Leukemia. The first column contains the cancer type, with **0 indicating the ALL** class and **1 indicating the AML** class. Columns 2-7130 contain expression levels of 7129 genes recorded from each tissue sample. \n",
    "\n",
    "In the following questions, we will use linear and logistic regression to build classification models for this data set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Question 1 [20 pts]: Data Exploration </b></div>\n",
    "\n",
    "First step is to  split  the observations into an approximate 80-20 train-test split.  Below is some code to do this for you (we want to make sure everyone has the same splits). Print dataset shape before splitting and after splitting. `Cancer_type` is our target column.\n",
    "\n",
    "\n",
    "**1.1** Take a peek at your training set (show a glimpse of what you did): you should notice the severe differences in the measurements from one gene to the next (some are negative, some hover around zero, and some are well into the thousands).  To account for these differences in scale and variability, normalize each predictor to vary between 0 and 1.\n",
    "\n",
    "\n",
    "**1.2** The training set contains more predictors than observations. What problem(s) can this lead to in fitting a classification model to such a data set? Explain in 3 or fewer sentences.\n",
    "\n",
    "\n",
    "**1.3** Identify and report which 10 genes individually discriminate between the two cancer classes the best (consider every gene in the data set).  Note: it wil lbe useful to save this list for future parts.\n",
    "\n",
    "Plot two histograms ofyour best predictor - one using training and another for the testing dataset. Each histogram should clearly distinguish two different `Cancer_type` classes.\n",
    "\n",
    "Hint: You may use t-testing to make this determination: #https://en.wikipedia.org/wiki/Welch%27s_t-test.\n",
    "\n",
    "\n",
    "**1.4** Using your top gene from the previous part (call it  `best_predictor`), create a classification model by manually eye-balling a value for this gene that would discriminate the two classes the best. Justify your choice in 1-2 sentences. Report the accuracy of this hand-chosen model on the test set.\n",
    "\n",
    "<hr> <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First step is to split the observations into an approximate 80-20 train-test split. Below is some code to do this for you (we want to make sure everyone has the same splits). Print dataset shape before splitting and after splitting. `Cancer_type` is our target column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "df = pd.read_csv('data/hw4_enhance.csv', index_col=0)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(df.loc[:, df.columns != 'Cancer_type'], \n",
    "                                                         df.Cancer_type, test_size=0.2, \n",
    "                                                         random_state = 109, \n",
    "                                                         stratify = df.Cancer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(752, 7130)\n",
      "(601, 7129) (151, 7129) (601,) (151,)\n",
      "0.0    0.511968\n",
      "1.0    0.488032\n",
      "Name: Cancer_type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.shape)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(df.Cancer_type.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Take a peek at your training set (show a glimpse of what you did): you should notice the severe differences in the measurements from one gene to the next (some are negative, some hover around zero, and some are well into the thousands).  To account for these differences in scale and variability, normalize each predictor to vary between 0 and 1.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFFX-BioB-5_at</th>\n",
       "      <th>AFFX-BioB-M_at</th>\n",
       "      <th>AFFX-BioB-3_at</th>\n",
       "      <th>AFFX-BioC-5_at</th>\n",
       "      <th>AFFX-BioC-3_at</th>\n",
       "      <th>AFFX-BioDn-5_at</th>\n",
       "      <th>AFFX-BioDn-3_at</th>\n",
       "      <th>AFFX-CreX-5_at</th>\n",
       "      <th>AFFX-CreX-3_at</th>\n",
       "      <th>AFFX-BioB-5_st</th>\n",
       "      <th>...</th>\n",
       "      <th>U48730_at</th>\n",
       "      <th>U58516_at</th>\n",
       "      <th>U73738_at</th>\n",
       "      <th>X06956_at</th>\n",
       "      <th>X16699_at</th>\n",
       "      <th>X83863_at</th>\n",
       "      <th>Z17240_at</th>\n",
       "      <th>L49218_f_at</th>\n",
       "      <th>M71243_f_at</th>\n",
       "      <th>Z78285_f_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>-83.669345</td>\n",
       "      <td>-129.202197</td>\n",
       "      <td>91.188553</td>\n",
       "      <td>-132.634919</td>\n",
       "      <td>-416.659258</td>\n",
       "      <td>-566.248620</td>\n",
       "      <td>-549.255222</td>\n",
       "      <td>-208.415176</td>\n",
       "      <td>213.331881</td>\n",
       "      <td>-135.518811</td>\n",
       "      <td>...</td>\n",
       "      <td>111.849800</td>\n",
       "      <td>371.083898</td>\n",
       "      <td>252.006568</td>\n",
       "      <td>963.153393</td>\n",
       "      <td>9.955941</td>\n",
       "      <td>142.181944</td>\n",
       "      <td>442.730023</td>\n",
       "      <td>42.848269</td>\n",
       "      <td>512.106908</td>\n",
       "      <td>4.677488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>-65.718571</td>\n",
       "      <td>-302.842019</td>\n",
       "      <td>-297.819728</td>\n",
       "      <td>-177.485917</td>\n",
       "      <td>-52.709137</td>\n",
       "      <td>-218.295750</td>\n",
       "      <td>195.983474</td>\n",
       "      <td>-268.235930</td>\n",
       "      <td>-328.630912</td>\n",
       "      <td>240.058672</td>\n",
       "      <td>...</td>\n",
       "      <td>252.867110</td>\n",
       "      <td>110.033722</td>\n",
       "      <td>203.197907</td>\n",
       "      <td>101.612259</td>\n",
       "      <td>-138.398658</td>\n",
       "      <td>245.767616</td>\n",
       "      <td>247.519122</td>\n",
       "      <td>-15.430358</td>\n",
       "      <td>-398.165984</td>\n",
       "      <td>-61.694246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>-264.191248</td>\n",
       "      <td>-162.255274</td>\n",
       "      <td>127.997172</td>\n",
       "      <td>173.771779</td>\n",
       "      <td>-185.191211</td>\n",
       "      <td>40.011778</td>\n",
       "      <td>-1562.983106</td>\n",
       "      <td>-85.344926</td>\n",
       "      <td>-119.622143</td>\n",
       "      <td>219.619110</td>\n",
       "      <td>...</td>\n",
       "      <td>20.797496</td>\n",
       "      <td>-184.115075</td>\n",
       "      <td>-227.872398</td>\n",
       "      <td>140.876523</td>\n",
       "      <td>42.543763</td>\n",
       "      <td>28.594281</td>\n",
       "      <td>204.479474</td>\n",
       "      <td>9.831559</td>\n",
       "      <td>21.718266</td>\n",
       "      <td>19.522122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-92.558574</td>\n",
       "      <td>-109.788332</td>\n",
       "      <td>379.542547</td>\n",
       "      <td>391.641129</td>\n",
       "      <td>-184.507364</td>\n",
       "      <td>-577.178389</td>\n",
       "      <td>-293.421369</td>\n",
       "      <td>-372.534572</td>\n",
       "      <td>190.551199</td>\n",
       "      <td>-487.331438</td>\n",
       "      <td>...</td>\n",
       "      <td>180.678776</td>\n",
       "      <td>577.889184</td>\n",
       "      <td>-50.443125</td>\n",
       "      <td>417.586154</td>\n",
       "      <td>-11.190519</td>\n",
       "      <td>1478.997020</td>\n",
       "      <td>15.923333</td>\n",
       "      <td>112.986515</td>\n",
       "      <td>-107.706335</td>\n",
       "      <td>-25.673203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>-143.099813</td>\n",
       "      <td>140.202023</td>\n",
       "      <td>-147.163850</td>\n",
       "      <td>222.339115</td>\n",
       "      <td>-231.007621</td>\n",
       "      <td>-753.616356</td>\n",
       "      <td>274.500343</td>\n",
       "      <td>-217.513332</td>\n",
       "      <td>-107.135509</td>\n",
       "      <td>-62.470938</td>\n",
       "      <td>...</td>\n",
       "      <td>139.821329</td>\n",
       "      <td>909.588696</td>\n",
       "      <td>43.531613</td>\n",
       "      <td>718.462679</td>\n",
       "      <td>-58.238405</td>\n",
       "      <td>232.494165</td>\n",
       "      <td>754.787059</td>\n",
       "      <td>-58.160474</td>\n",
       "      <td>1808.764690</td>\n",
       "      <td>-20.782346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AFFX-BioB-5_at  AFFX-BioB-M_at  AFFX-BioB-3_at  AFFX-BioC-5_at  \\\n",
       "486      -83.669345     -129.202197       91.188553     -132.634919   \n",
       "604      -65.718571     -302.842019     -297.819728     -177.485917   \n",
       "341     -264.191248     -162.255274      127.997172      173.771779   \n",
       "117      -92.558574     -109.788332      379.542547      391.641129   \n",
       "516     -143.099813      140.202023     -147.163850      222.339115   \n",
       "\n",
       "     AFFX-BioC-3_at  AFFX-BioDn-5_at  AFFX-BioDn-3_at  AFFX-CreX-5_at  \\\n",
       "486     -416.659258      -566.248620      -549.255222     -208.415176   \n",
       "604      -52.709137      -218.295750       195.983474     -268.235930   \n",
       "341     -185.191211        40.011778     -1562.983106      -85.344926   \n",
       "117     -184.507364      -577.178389      -293.421369     -372.534572   \n",
       "516     -231.007621      -753.616356       274.500343     -217.513332   \n",
       "\n",
       "     AFFX-CreX-3_at  AFFX-BioB-5_st  ...   U48730_at   U58516_at   U73738_at  \\\n",
       "486      213.331881     -135.518811  ...  111.849800  371.083898  252.006568   \n",
       "604     -328.630912      240.058672  ...  252.867110  110.033722  203.197907   \n",
       "341     -119.622143      219.619110  ...   20.797496 -184.115075 -227.872398   \n",
       "117      190.551199     -487.331438  ...  180.678776  577.889184  -50.443125   \n",
       "516     -107.135509      -62.470938  ...  139.821329  909.588696   43.531613   \n",
       "\n",
       "      X06956_at   X16699_at    X83863_at   Z17240_at  L49218_f_at  \\\n",
       "486  963.153393    9.955941   142.181944  442.730023    42.848269   \n",
       "604  101.612259 -138.398658   245.767616  247.519122   -15.430358   \n",
       "341  140.876523   42.543763    28.594281  204.479474     9.831559   \n",
       "117  417.586154  -11.190519  1478.997020   15.923333   112.986515   \n",
       "516  718.462679  -58.238405   232.494165  754.787059   -58.160474   \n",
       "\n",
       "     M71243_f_at  Z78285_f_at  \n",
       "486   512.106908     4.677488  \n",
       "604  -398.165984   -61.694246  \n",
       "341    21.718266    19.522122  \n",
       "117  -107.706335   -25.673203  \n",
       "516  1808.764690   -20.782346  \n",
       "\n",
       "[5 rows x 7129 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying first few columns of training set\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data - following Section 4\n",
    "\n",
    "# IS IT CORRECT TO NORMALIZE X_train and y_train SEPARATELY??\n",
    "# Normalize X_train\n",
    "X_train = MinMaxScaler().fit_transform(X_train)  # turns it into a numpy array\n",
    "X_train = pd.DataFrame(X_train)   # need to turn it back into a dataframe\n",
    "\n",
    "# Normalize y_train\n",
    "# turn into nx1 matrix first\n",
    "y_reshaped = np.array(y_train).reshape(-1,1)\n",
    "y_train = MinMaxScaler().fit_transform(y_reshaped)\n",
    "y_train = pd.DataFrame(y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 The training set contains more predictors than observations. What problem(s) can this lead to in fitting a classification model to such a data set? Explain in 3 or fewer sentences.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having more predictors than observations is almost certainly leading to multicollinearity among the predictors. This would be because there wouldn't be unique solutions for every single predictor or variable meaning that some predictors could be linearly dependent on other predictors. This is a problem that we would fix with cross validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3** **Identify and report which 10 genes individually discriminate between the two cancer classes the best (consider every gene in the data set).  Note: it wil lbe useful to save this list for future parts.**\n",
    "\n",
    "**Plot two histograms of your best predictor - one using training and another for the testing dataset. Each histogram should clearly distinguish two different `Cancer_type` classes.**\n",
    "\n",
    "**Hint: You may use t-testing to make this determination: #https://en.wikipedia.org/wiki/Welch%27s_t-test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-tests to identify genes\n",
    "\n",
    "# create empy list to store p values\n",
    "p_values = []\n",
    "\n",
    "# Use a for loop to test and record p-values for each gene?\n",
    "    # for cur_val in X_train.columns:\n",
    "    # calculate means\n",
    "    # calculate standard deviations\n",
    "    # construct t statistic (on the two cancer types maybe??)\n",
    "    # t = (a.mean() - b.mean())/(s*np.sqrt(2/N))\n",
    "    \n",
    "    # idenitify degrees of freedom - N is length of column?\n",
    "    # df = 2*N - 2\n",
    "    \n",
    "    # use p_val = 1 - stats.t.cdf(t,df=df)\n",
    "    \n",
    "    # append p to pvalue list\n",
    "    # p_values.append(p_val)\n",
    "    \n",
    "# sort p_values list, take first 10?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4 Using your top gene from the previous part (call it  `best_predictor`), create a classification model by eye-balling a value for this gene that would discriminate the two classes the best. Justify your choice in 1-2 sentences. Report the accuracy of this hand-chosen model on the test set.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Question 2 [25 pts]: Linear and Logistic Regression  </b></div>\n",
    "\n",
    "\n",
    "In class we discussed how to use both linear regression and logistic regression for classification. For this question, you will work with a single gene predictor that you identify as the best predictor above to explore these two methods.\n",
    "\n",
    "**2.1** Fit a simple linear regression model to the training set using the single gene predictor `best_predictor` to predict cancer type. The scores predicted by the regression model for a patient could be interpreted as an estimate of the probability that the patient has Cancer_type=1 (AML). Is there a problem with this interpretation?\n",
    "\n",
    "\n",
    "Create a figure with following items displayed on the same plot (use training data):\n",
    " - the predicted quantitative response from the linear regression model as a function of the best gene predictor\n",
    " - the true binary response. \n",
    "\n",
    "\n",
    "**2.2** Use your estimated linear regression model to classify observations into 0 and 1 using the standard Bayes' classifier.  Evaluate the classification accuracy of this classification model on both the training and test sets.\n",
    "\n",
    "\n",
    "**2.3** Next, fit a simple logistic regression model to the training set. How do the training and test classification accuracies of this model compare with the linear regression model? \n",
    "\n",
    "Remember, you need to set the regularization parameter for sklearn's logistic regression function to be a very large value in order to **not** regularize (use 'C=100000'). \n",
    "\n",
    "\n",
    "**2.4** \n",
    "Print and interpret the logistic regression coefficients: the 'slope' and intercept. \n",
    "\n",
    "\n",
    "Create 2 plots (one each for training and testing data) with 4 items displayed on each plot.\n",
    "- the predicted quantitative response from the linear regression model as a function of the best gene predictor.\n",
    "- the predicted probabilities of the logistic regression model as a function of the best gene predictor. \n",
    "- the true binary response. \n",
    "- a horizontal line at $y=0.5$. \n",
    "\n",
    "Based on these plots, does one of the models appear better suited for binary classification than the other?  Explain in 3 sentences or fewer. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** **Fit a simple linear regression model to the training set using the single gene predictor `best_predictor` to predict cancer type. The scores predicted by the regression model for a patient could be interpreted as an estimate of the probability that the patient has Cancer_type=1 (AML).  Is there a problem with this interpretation?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** **Use your estimated linear regression model to classify observations into 0 and 1 using the standard Bayes' classifier.  Evaluate the classification accuracy of this classification model on both the training and test sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**2.3** **Next, fit a simple logistic regression model to the training set. How do the training and test classification accuracies of this model compare with the linear regression model? Are the classifications substantially different?  Explain why this is the case.**\n",
    "\n",
    "**Remember, you need to set the regularization parameter for sklearn's logistic regression function to be a very large value in order to **not** regularize (use 'C=100000')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Print and interpret the logistic regression coefficients: the 'slope' and the intercept.**\n",
    "\n",
    "**Create 2 plots (with training and test data) with 4 items displayed on each plot.**\n",
    "- the predicted quantitative response from the linear regression model as a function of the best gene predictor.\n",
    "- the predicted probabilities of the logistic regression model as a function of the best gene predictor. \n",
    "- the true binary response. \n",
    "- a horizontal line at $y=0.5$.\n",
    "\n",
    "**Based on these plots, does one of the models appear better suited for binary classification than the other?  Explain in 3 sentences or fewer.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 3 [20pts]: Multiple Logistic Regression </b> </div>\n",
    "\n",
    "\n",
    "**3.1** Next, fit a multiple logistic regression model with all the gene predictors from the data set.  How does the classification accuracy of this model compare with the models fitted in question 2 with a single gene (on both the training and test sets)?  \n",
    "\n",
    "\n",
    "**3.2** How many of the coefficients estimated by this multiple logistic regression in the previous part are significantly different from zero at a *significance level of 5%*? Use the same value of C=100000 as before.\n",
    "\n",
    "**Hint:** To answer this question, use *bootstrapping* with 100 bootstrap samples/iterations.  \n",
    "\n",
    "\n",
    "**3.3** Comment on the classification accuracy of training and test set? Given the results above how would you assess the generalization capacity of your trained model? What other tests would you suggest to better guard against false sense of security on the accuracy of the model as a whole? \n",
    "\n",
    "**3.4** Now use regularization to improve predictions from the multiple logistic regression model.  Use LASSO-like regularization and cross-validation within the training set to tune the model.  Report the classification accuracy on both the training and test set.\n",
    "\n",
    "**3.5** Do the 10 best predictors from Q1 hold up as important features in this regularized model?  If not, explain why this is the case (feel free to use the data to support your explanation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** **Next, fit a multiple logistic regression model with all the gene predictors from the data set.  How does the classification accuracy of this model compare with the models fitted in question 2 with a single gene (on both the training and test sets)?**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkv09\\Anaconda3\\envs\\cs109a\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kkv09\\Anaconda3\\envs\\cs109a\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# following lab 6\n",
    "# instantiate logistic regression model\n",
    "lr = LogisticRegression()\n",
    "# fit the data on the training set\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2** **How many of the coefficients estimated by this multiple logistic regression in the previous part are significantly different from zero at a *significance level of 5%*? Use the same value of C=100000 as before.**\n",
    "\n",
    "**Hint:** **To answer this question, use *bootstrapping* with 1000 bootstrap samples/iterations.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Open question: Comment on the classification accuracy of training and test set? Given the results above how would you assest the generalization capacity of your trained model? What other tests would you suggest to better guard against false sense of security on the accuracy of the model as a whole.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4 Now use regularization to improve predictions from the multiple logistic regression model.  Use LASSO-like regularization and cross-validation within the training set to tune the model.  Report the classification accuracy on both the training and test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5: Do the 10 best predictors from Q1 hold up as important features in this regularized model?  If not, explain why this is the case (feel free to use the data to support your explanation).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 4 [25pts]: Multi Class Log Regression </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1** Load the data from `hw4_mc_enhance.csv.zip` and examine its structure. How many instances of each class are there in our dataset? \n",
    "\n",
    "**4.2** Split the dataset into train and test, 80-20 split, random_state = 8. \n",
    "\n",
    "We are going to utilize these two features - 'M31523_at', 'X95735_at'.  Create a scatter plot of these two features using the training dataset.  It should be easily discernable via labeling/marking in the plot which observations belong to which `cancer_type`.\n",
    "\n",
    "**4.3** Fit the following two models using crossvalidation: \n",
    "- Logistic Regression Multiclass model with linear features. \n",
    "- Logistic Regression Multiclass model with Polynomial features, degree = 2.\n",
    "\n",
    "**4.4** Plot the decision boundaries for each model and interpret the results. Hint: You may utilize the function `overlay_decision_boundary`. \n",
    "\n",
    "**4.5** Report and plot the CV scores for the two models and interpret. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1 Load the data from `hw4_mc_enhance.csv.zip` and examine its structure. How many instances of each class are there in our dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open zipfile first\n",
    "z = zipfile.ZipFile(\"data/hw4_mc_enhance.csv.zip\")\n",
    "# load the right one into a dataframe\n",
    "df2 = pd.read_csv(z.open('hw4_mc_enhance.csv'), index_col=0)\n",
    "\n",
    "# Examining structure\n",
    "print(df2.shape)\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0    0.333333\n",
      "1.0    0.333333\n",
      "0.0    0.333333\n",
      "Name: cancer_type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Finding instances of each class\n",
    "print(df2.cancer_type.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Split the dataset into train and test, 80-20 split, random_state = 8.**\n",
    "\n",
    "**We are going to utilize these two features - 'M31523_at', 'X95735_at'.  Create a scatter plot of these two features using training dataset.  We should be able to discern from the plot which sample belongs to which `cancer_type`.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi =train_test_split(df2.loc[:, df2.columns != 'Cancer_type'], \n",
    "                                                         df2.cancer_type, test_size=0.2, \n",
    "                                                         random_state = 8, \n",
    "                                                         stratify = df2.cancer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using seaborn - following lab 5\n",
    "sns.pairplot(X_train_multi.loc[:,['M31523_at', 'X95735_at']]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3  Fit the following two models using crossvalidation:**\n",
    "\n",
    "**Logistic Regression Multiclass model with linear features.**\n",
    "\n",
    "**Logistic Regression Multiclass model with Polynomial features, degree = 2.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4 Plot the decision boundary and interpret results. Hint: You may utilize the function `overlay_decision_boundary`** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_decision_boundary(ax, model, colors=None, nx=200, ny=200, desaturate=.5, xlim=None, ylim=None):\n",
    "    \"\"\"\n",
    "    A function that visualizes the decision boundaries of a classifier.\n",
    "    \n",
    "    ax: Matplotlib Axes to plot on\n",
    "    model: Classifier to use.\n",
    "     - if `model` has a `.predict` method, like an sklearn classifier, we call `model.predict(X)`\n",
    "     - otherwise, we simply call `model(X)`\n",
    "    colors: list or dict of colors to use. Use color `colors[i]` for class i.\n",
    "     - If colors is not provided, uses the current color cycle\n",
    "    nx, ny: number of mesh points to evaluated the classifier on\n",
    "    desaturate: how much to desaturate each of the colors (for better contrast with the sample points)\n",
    "    xlim, ylim: range to plot on. (If the default, None, is passed, the limits will be taken from `ax`.)\n",
    "    \"\"\"\n",
    "    # Create mesh.\n",
    "    xmin, xmax = ax.get_xlim() if xlim is None else xlim\n",
    "    ymin, ymax = ax.get_ylim() if ylim is None else ylim\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(xmin, xmax, nx),\n",
    "        np.linspace(ymin, ymax, ny))\n",
    "    X = np.c_[xx.flatten(), yy.flatten()]\n",
    "\n",
    "    # Predict on mesh of points.\n",
    "    model = getattr(model, 'predict', model)\n",
    "    y = model(X)\n",
    "    #print(\"Do I predict\" , y)\n",
    "    \n",
    "    \n",
    "#     y[np.where(y=='aml')]=3\n",
    "#     y[np.where(y=='allT')]=2\n",
    "#     y[np.where(y=='allB')]=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    y = y.astype(int) # This may be necessary for 32-bit Python.\n",
    "    y = y.reshape((nx, ny))\n",
    "\n",
    "    # Generate colormap.\n",
    "    if colors is None:\n",
    "        # If colors not provided, use the current color cycle.\n",
    "        # Shift the indices so that the lowest class actually predicted gets the first color.\n",
    "        # ^ This is a bit magic, consider removing for next year.\n",
    "        colors = (['white'] * np.min(y)) + sns.utils.get_color_cycle()\n",
    "\n",
    "    if isinstance(colors, dict):\n",
    "        missing_colors = [idx for idx in np.unique(y) if idx not in colors]\n",
    "        assert len(missing_colors) == 0, f\"Color not specified for predictions {missing_colors}.\"\n",
    "\n",
    "        # Make a list of colors, filling in items from the dict.\n",
    "        color_list = ['white'] * (np.max(y) + 1)\n",
    "        for idx, val in colors.items():\n",
    "            color_list[idx] = val\n",
    "    else:\n",
    "        assert len(colors) >= np.max(y) + 1, \"Insufficient colors passed for all predictions.\"\n",
    "        color_list = colors\n",
    "    color_list = [sns.utils.desaturate(color, desaturate) for color in color_list]\n",
    "    cmap = matplotlib.colors.ListedColormap(color_list)\n",
    "\n",
    "    # Plot decision surface\n",
    "    ax.pcolormesh(xx, yy, y, zorder=-2, cmap=cmap, norm=matplotlib.colors.NoNorm(), vmin=0, vmax=y.max() + 1)\n",
    "    xx = xx.reshape(nx, ny)\n",
    "    yy = yy.reshape(nx, ny)\n",
    "    if len(np.unique(y)) > 1:\n",
    "        ax.contour(xx, yy, y, colors=\"black\", linewidths=1, zorder=-1)\n",
    "    else:\n",
    "        print(\"Warning: only one class predicted, so not plotting contour lines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.5 Report and plot the CV scores for the two models and interpret.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Question 5: [10 pts] Including an 'abstain' option </b></div>\n",
    "\n",
    "One of the reasons a hospital might be hesitant to use your cancer classification model is that a misdiagnosis by the model on a patient can sometimes prove to be very costly (e.g. if the patient were to file a law suit seeking a compensation for damages). One way to mitigate this concern is to allow the model to 'abstain' from making a prediction: whenever it is uncertain about the diagnosis for a patient. However, when the model abstains from making a prediction, the hospital will have to forward the patient to a specialist, which would incur additional cost.  How could one design a cancer classification model with an abstain option, such that the cost to the hospital is minimized?\n",
    "\n",
    "*Hint:* Think of ways to build on top of the logistic regression model and have it abstain on patients who are difficult to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1** More specifically, suppose the cost incurred by a hospital when a model mis-predicts on a patient is $\\$5000$ , and the cost incurred when the model abstains from making a prediction is \\$1000. What is the average cost per patient for the OvR logistic regression model (without quadratic or interaction terms) from **Question 4**.  Note that this needs to be evaluated on the patients in the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2** Design a classification strategy (into the 3 groups plus the *abstain* group) that has as low cost as possible per patient (certainly lower cost per patient than the logistic regression model).   Give a justification for your approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 More specifically, suppose the cost incurred by a hospital when a model mis-predicts on a patient is $\\$5000$ , and the cost incurred when the model abstains from making a prediction is \\$1000. What is the average cost per patient for the OvR logistic regression model (without quadratic or interaction terms) from Question 4.  Note that this needs to be evaluated on the patients in the test set.**\n",
    "**\n",
    "...\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 Design a classification strategy (into the 3 groups plus the *abstain* group) that has as low cost as possible per patient (certainly lower cost per patient than the logistic regression model).   Give a justification for your approach.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
